\subsection{Overview}
\label{sec:overview}
Figure \ref{fig:goat_workflow} displays the workflow of \goat to achieve objectives acquainted in section \ref{sec:intro}.
%
Given a program \textbf{P} (\ie, a set of Go source files with a \textit{main} function), \goat automatically instruments \textbf{P} and constructs static and dynamic models of execution for thorough testing and analysis.
%
\goat's main objective is to facilitate the investigation of \textit{non-deterministic interactions between concurrent components} (\ie, concurrent behavior) of \textbf{P}.
%
\goat's work starts with parsing source files to identify the location of concurrency primitive usages in \textbf{P}.
%
A static model \textbf{M} is constructed from the identified concurrency primitives (section \ref{sec:static_analysis}) for two purposes.
%
First, \goat employs \textbf{M} to instrument \textbf{P} with handlers to \goat API for dynamic tracing and schedule space exploration (section \ref{sec:dynamic_analysis}).
%
Second, a set of coverage requirements is extracted from \textbf{M} to get examined during testing iterations (section \ref{sec:covreq}).
%
Once the execution of \textbf{P} terminates (\eg, successfully exits, fails, times out), an ECT containing a sequence of executed events is generated for offline analysis (section \ref{sec:offline_analysis}).
%
As soon as \goat detects a bug or the coverage exceeds a threshold, it stops running and produces reports for manual analysis by the user.
%
The remainder of this section describes the design and implementation of each component.

\subsection{Static Analysis}
\label{sec:static_analysis}

\subsubsection{Concurrency Usage Model}
\goat statically constructs a model \textbf{M} from the usage of concurrency primitives in \textbf{P} files which enables uniform analysis during testing iterations.
%
\textbf{M} is a table of source locations (files and line numbers) associated with \textit{concurrency usages} (CU).
%
We define CU as a triple of $(f,l,k)$ where $f$ is the file name, $l$ is the line number and $k$ is the kind of concurrency primitive used in the code location.
Kind $k\in$ \texttt{Channel} $\cup$ \texttt{Sync} $\cup$ \texttt{Go} where:
\begin{itemize}
  \item \texttt{Channel} = \{\texttt{send}, \texttt{receive}, \texttt{close}\}
  \item \texttt{Sync} = \{\texttt{lock}, \texttt{unlock}, \texttt{wait}, \texttt{add}, \texttt{done}, \texttt{signal}, \texttt{broadcast}\}
  \item \texttt{Go} = \{\texttt{go}, \texttt{select}, \texttt{range}\}
\end{itemize}

\goat constructs \textbf{M} by traversing the \textit{abstract syntax tree} (AST) for each file in \textbf{P} using the Go AST package~\cite{go-package-ast}.
%
The first column of table \ref{tab:moby_cov_table} shows the CU locations extracted from program in listing \ref{listing:moby28462.minipage}.
%
%Investigating such actions is essential in the correctness analysis of \textbf{P} as they characterize the \textbf{P}'s concurrent behavior.
%
By injecting random and bounded yields before each entry in \textbf{M}, \goat explores attainable scenarios and accelerates the discovery of rare bugs.
%
In section \ref{sec:covreq}, we describe the other advantage of the model \textbf{M} in defining concurrent coverage requirements and their dynamic measurements.

%


\subsubsection{Source Instrumentation}
During the AST traversal and construction of \textbf{M}, \goat also identifies the main function to equip \textbf{P} with the concurrency tracing mechanism.
%
The invocations of \goat API are injected to the AST of \textbf{P}'s main function to guarantee end-to-end tracing from \textbf{P}'s execution.
%
Additionally, \goat uses \textbf{M} to inject yield handlers before all CU source locations in \textbf{P}'s AST to enable schedule perturbation.
%
ASTs are then rewritten into Go source files in a separate folder for further analysis.
%
Details about the design of \goat API are explained in section \ref{sec:dynamic_analysis}.

\subsection{Coverage Requirements}
\label{sec:covreq}
The effectiveness of testing concurrent software is assessed by observing possible behaviors of concurrent components during testing iterations.
%
We emulate the possible behavior of concurrent components by defining a set of \textit{coverage requirements} and measuring whether they are covered during testing.
%
Based on our investigations from the execution of Go applications and bug kernels, we define a set of coverage requirements (summarized in table \ref{tab:cov_req}) that emulates the dynamic behavior of concurrent primitives:
%
\begin{itemize}
  \item \textbf{Req1 (Send/Recv):} \{\texttt{blocked}, \texttt{unblocking}, \texttt{NOP}\} -- Goroutine $G_1$ is either \textit{blocked} on a channel send (receive) if the receiver (sender) goroutine $G_2$ is not ready, or \textit{unblocking} the waiting receiver (sender) goroutine $G_2$. A channel send or receive might also be neither blocked nor unblocking (NOP) for buffered channels.
  \item \textbf{Req2 (Select-Case):} \{\texttt{blocked}, \texttt{unblocking}, \texttt{NOP}\} $\times$ \{\texttt{case}$_i$\} -- cases of select statements are channel sends and recives (or default case for non-blocking selects). For all select statements that has no default case, we obtain the cases of each select statement at runtime and maintain an instance of Req1 per case.
  \item \textbf{Req3 (Lock):} \{\texttt{blocked}, \texttt{blocking}\} -- Goroutine $G_i$ is either \textit{blocked} when locking a mutex because another goroutine has locked the mutex or \textit{blocking} other goroutines from acquiring the mutex lock.
  \item \textbf{Req4 (Unblocking):} \{\texttt{unblocking}, \texttt{NOP}\} -- The goroutine that is performing channel close, mutex unlock, conditional variable signal and broadcast, waitGroup done, and non-blocking select case (send or receive) either \textit{unblocks} one or more blocked goroutines or has no effect (NOP).
  \item \textbf{Req5-Go:} \{\texttt{NOP}\} -- We emit a NOP action for each goroutine creation to indicate that it is covered during testing.
\end{itemize}


\begin{table}[]
\centering
\caption{Coverge requirements defined for concurrent Go}
\scalebox{0.83}{
\input{tabs/coverage_requirements.tex}
}
\label{tab:cov_req}
\end{table}

%
With the help of \goat's infrastructure, the proposed requirements satisfy the characteristics of an ``acceptable'' coverage metric because:
\begin{enumerate}
  \item A \textit{static model} \textbf{M} from program \textbf{P} is obtained by identifying its CU points. \textbf{M} is easy to understand by developers and reflects the concurrent behavior of \textbf{P}.
  \item The defined requirements are \textit{measurable} by analyzing the test's ECT. A global data structure maintains the covered requirements by each $t \in \mathcal{T}$ (the coverage measurement mechanism is explained in section \ref{sec:dynamic_analysis}).
  \item Upon completion of $\mathcal{T}$ iterations, the \textit{uncovered} requirements imply some \textit{meaningful} information about the behavior of \textbf{P}. For example, if a send is always performing as \textit{unblocking} and never as \textit{blocked}, it means that the receiver always performs receive before the sender reaches its send instruction. In other words, the receive action \textit{always happen-before} send action. This communication pattern might be part of \textbf{P}'s semantics and matches the developer's expectations (e.g., a set of goroutines are listening on a channel to perform non-frequent requests). Otherwise, the uncovered requirement  ``send-\texttt{blocked}'' reflects a bug or flaw in the program design.
  \item Since \goat can detect occurred blocking bugs and maintain a global coverage model, $\mathcal{T}$ iterations terminate either by detecting a bug or reaching a coverage percentage threshold.
\end{enumerate}

%Each of these requirements accurately displays possible behavior for each concurrent component.
%
%Increasing the coverage percentage of the above requirements improves confidence in the thoroughness of the tests.

%\stcmt{fix below with more accurate description}
%In section \ref{sec:evaluation}, we show that the increased rate of coverage is in a linear correlation with the bug exposure rate.

\subsection{Dynamic Analysis}
\label{sec:dynamic_analysis}
The primary cause of most real-world concurrent bugs is the misuse of concurrency features like channels, mutexes, and waitGroups (table \ref{tab:comparison}).
%
To gain insight into the behavior of concurrency features during execution, we equipped \goat with a tracing mechanism, which is an extension to the Go built-in tracer package~\cite{go-cmd-trace}.
%
The tracing capability is compiled into all programs always through the runtime and is enabled on demand -- when tracing is disabled, it has minimal runtime overhead \cite{go-exec-tracer-doc}.
%
We chose the tracer package to enhance because it 1) is already compiled into the runtime, 2) adds minimal overhead, and 3) only lacks some pieces allowing the construction of an accurate concurrency model.
%
%The concurrency tracing capability is added to the original Go runtime through a one-time patch.

\subsubsection{Concurrency Tracing}
\textit{Execution concurrency trace} (ECT) is a totally ordered \textit{sequence} of events in which the order is approximated through a central clock with nanosecond precision.
%
ECT also contains the call-stack for each event, enabling a direct mapping of events to source-line numbers.
%
The alphabet of ECT is total of 63 events -- 49 from original tracer package \cite{goParserSource}, categorized and summarized in table \ref{tab:events} and 14 additional events that we added to capture concurrency usage events:
%
\begin{itemize}
    \item \textbf{Channel:} For each channel operation (make, send, receive, close), ECT includes an event with a unique id assigned to each channel.
    \item \textbf{(RW)Mutex, WaitGroup \& Conditional Variables:} Similar to channels, we assign a unique id to each concurrency object and emit an event for each of their operations (lock, unlock, rlock, runlock, add, wait, signal, broadcast).
    \item \textbf{Select \& Schedule:} The scheduler and the \textit{select} structure introduce non-determinism to the execution. We keep track of the decisions made by the scheduler and select statements to obtain an accurate decision path during execution.
\end{itemize}

%\stcmtside{how ECT captures concurrency blocking behavior}


%
For each blocking operation (channels \textit{sends}/\textit{recvs}, mutex \textit{locks}, waitGroup/conditional variable \textit{wait} and \textit{select} (when none of the cases are available)), ECT captures a pair of pre-operation and post-operation events to distinguish between the \textit{request for action} and \textit{completion of action}.
%
Hence, ECT is especially effective for debugging because it enables modeling the blocking state of the program at any given step of execution.
%
It also assists in measuring the coverage requirements during testing to study the behavior of concurrency primitives.
%
More details about the implementation of trace package enhancement and scalability report are available in \cite{ect-arxiv}.

\begin{table}[]
    \centering
        \caption{Event categories by the Go execution tracer}
        \begin{tabular}{|l|l|}
        \hline
        \rowcolor[HTML]{C0C0C0}
        \multicolumn{1}{|c|}{\cellcolor[HTML]{C0C0C0}\textbf{Category}} & \multicolumn{1}{c|}{\cellcolor[HTML]{C0C0C0}\textbf{Description}} \\ \hline
        Process & Indication of process/thread start and stop \\ \hline
        GC/Mem & Garbage collection and memory operation events\\ \hline
        Goroutine & Goroutines events: create, block, start, stop, end, etc. \\ \hline
        Syscall & Interactions with system calls \\ \hline
        Users & User annotated regions and tasks (for bounded tracing) \\ \hline
        Misc & System related events like futile wakeup or timers \\ \hline
        \end{tabular}
    \label{tab:events}
\end{table}

\subsubsection{\goat API}
As we described in section \ref{sec:static_analysis}, we inject three statements to \textbf{P} that invokes functions from the \goat API:
\begin{itemize}
  \item \texttt{goat\_done := goat.Start()} initializes \goat, enables tracing, and returns a channel as a conduit between application space and \goat.
  \item \texttt{go goat.Watch(goat\_done)} spawns a new goroutine as a watchdog for the liveness of the program (in case of global deadlock or infinite loop). The watcher goroutine either receives from \texttt{goat\_done} and sends back an ack signal or timeouts (default: 30 seconds). Then it stops tracing, flushing the trace buffer, and terminates.
  \item \texttt{defer goat.Stop(goat\_done)} sends a value to the watcher goroutine after main returns and signals that the program is finished. Then it waits to receive the signal from the watcher, then stops tracing and terminates.
\end{itemize}

We also inject calls to \texttt{goat.handler()} before each CU in \textbf{M} to manipulate the native scheduler. \texttt{goat.handler()} is a function invocation that randomly calls \texttt{runtime.GoSched()} (within a bound $D$) to preempt the processing core from current goroutine and push the goroutine to the back of the global queue of runnable goroutines.
%
%\stcmt{fix below with more accurate description of}
Our experiments (section \ref{sec:evaluation}) demonstrate that the optimum value for $D$ is not larger than 3, showing that even a small number of yields is effective in exposing the bug (as also shown in \cite{burckhardt-depthBug-asplos10}).

\subsection{Offline Analysis}
\label{sec:offline_analysis}
Upon program execution termination, \goat constructs a \textit{goroutine tree} (figure \ref{fig:gtree}) of application goroutines from the generated ECT.
%
Nodes in the goroutine tree represent an application-level goroutine, and directed edges denote parent-child relationships in which the child is created from a \texttt{go} statement that the parent executes.
%
Each node of the tree contains the entire sequence of events that the goroutine executed (not shown in the figure for simplicity), information about the goroutine's creation site, the resources it holds at each execution point, and the final executed event right before program termination.
%
\goat analyzes this collection of information to check whether any goroutine leaked after termination and whether the coverage requirements are covered.

\subsubsection{Deadlock Detection}
In the lifetime of a program, the runtime system creates new goroutines or pick from the pool of dead goroutines to perform various tasks such as bootstrapping the program, garbage marking and sweeping, and tracing.
%
\goat also adds an extra goroutine to \textit{watch} the program execution in case of the main goroutine blockage.
%
During tracing, these goroutines are captured, but they are irrelevant for application-level debugging.
%
By checking the stack of creation location, \goat prunes the goroutine tree and only keeps the \textit{application-level} goroutines.
%
We say a goroutine is an application-level goroutine if it is the main goroutine (that executes the main function) or it has all of the following conditions:
1) its ancestor is the main goroutine,
2) it is not a Go runtime system goroutine, and
3) it is not a tracer goroutine.
Such distinguishment between goroutines is essential to define the boundaries of the application and the underlying system.

\begin{figure}[]
\centering
\includegraphics[width=0.75\linewidth]{figs/gtree.pdf}
%\includegraphics[]{figs/overview.png}
%\includegraphics[]{figs/overv}
\caption{Goroutine tree of the leak situation in listing \ref{listing:moby28462.minipage}}
\label{fig:gtree}
\end{figure}

When tracing is enabled, every application goroutine invokes the tracer to capture $GoEnd$ before finishing its execution.
%
Before the main function returns, the main goroutine hands over the control to the root goroutine to finalize the program termination.
%
This context-switch is done through invocation of \texttt{runtime.Gosched()} which emits the $GoSched$ event.
%
In \goat, the main goroutine's final event in a successful execution is $GoSched$ with \texttt{runtime.traceStop} on top of its stack.
%

We call an execution \textbf{successful}, if below conditions hold:
\begin{enumerate}
  \item (1) all goroutines spawned in the main goroutine has $GoEnd$ as their final event
  \item (2) the final event of the main goroutine is $GoSched$ with \texttt{runtime.traceStop} on top of its stack.
\end{enumerate}

In the absence of any of these conditions, we conclude that the program suffers from a ``deadlock'' bug, because at least one goroutine did not reach its final state.
%
Therefore, \goat executes procedure \ref{proc:deadlockCheck} which is a BFS traversal on the goroutine tree to check if the program suffers from partial or global deadlocks.


\begin{small}
\begin{algorithm}[]
 \DontPrintSemicolon
 \SetKwFunction{KwDeadlockCheck}{DeadlockCheck}
% \SetKwInOut{Input}{Input} \SetKwInOut{Output}{Output}\SetKwInOut{Local}{Local}
  %\SetKw{KwEach}{each}
 %\Input{Stack of elements $S$, $S[1]$ is top}
 %\Output{$NLR(T)$}
 \KwDeadlockCheck{$G$}:{\\
 \Indp
    \If{$cur$.lastEvent$ \neq$ \texttt{GoSched}}{
      return \textbf{Global Deadlock}\;
    }
    $toVisit$ = $[G.children]$\;
    \For{ $|toVisit| \neq 0$}{
         $cur$ = $toVisit$[0]\;
         \If{$cur$.lastEvent $\neq$ \texttt{GoEnd}}{
            return \textbf{Partial Deadlock (leak)}\;
          }
         \For {$n$ in $cur.Children$}{
            append $n$ to $toVisit$\;
          }
          $toVisit = toVisit[1:]$\;
      }
      return \textbf{Pass}\;
  }
 \caption{\texttt{DeadlockCheck} procedure with root node of goroutine tree (main goroutine) as input}
 \label{proc:deadlockCheck}
\end{algorithm}
\end{small}


\begin{table}[]
\centering
\caption{Concurrency Usages and coverage requirements of program in listing\ref{listing:moby28462.minipage}}
\scalebox{0.9}{
\input{tabs/moby_coverage_table}
}
\label{tab:moby_cov_table}
\end{table}


%\stcmt{reports and visualizations}
When a deadlock is detected, \goat generates visualizations such as executed interleaving (listing \ref{listing:moby28462.minipage}) and goroutine tree (figure \ref{fig:gtree}).
%
The detailed report magnifies the scenario under which the bug has occurred and displays the final concurrent state of the program right before the failure.
%
In addition, custom logs and reports such as the ``happens-before'' log of a set of goroutines and their associated resources are easily generated through a replay of ECT.
%
Samples of such reports and visualizations are available in [appendix or online link]

\subsubsection{Coverage Measurement}
Once the program execution terminates, \goat checks whether the extracted coverage requirements are covered during execution.
%
A mapping between dynamic concurrent events and statically obtained CU points is emitted by matching their respective call-stack and CU source location.
%
Through a BFS traversal of the goroutine tree, we add a \textit{coverage vector} to each goroutine node from the emitted mapping.
%
Each element of the coverage vector is the respective covered value of the coverage requirement for the current goroutine node.
%
During executions of tests $t \in \mathcal{T}$, we maintain and update a global goroutine tree after each $t$.
%
It is crucial to maintain a global goroutine tree to measure the progress of coverage percentage over tests in $\mathcal{T}$.
%
However, equivalencing between two goroutines and their respective coverage vectors from different executions is non-trivial.
%
We say two goroutines $G_m$ and $G_n$ in the tests $t_i$ and $t_j$ are \textit{equivalent} (\ie falls into a identical node in the global goroutine tree) if their parents are equivalent and their creation source location (CU of kind \texttt{go}) are identical:
%
%\begin{equation}
%  G_m \equiv G_n   \text{if}
%  \begin{cases}
%    \text{parent}(G_m) \equiv \text{parent}(G_n)  \wedge \\
%    \text{CU(}G_m\text{).file} = \text{CU(}G_n\text{).file}  \wedge\\
%    \text{CU(}G_m\text{).line} = \text{CU(}G_n\text{).line} \\
%  \end{cases}
%\end{equation}


\begin{table*}[]
\caption{Output of each tool on GoKer \cite{yuan-gobench-cgo21} blocking bugs. Detected bug (minimum \# of executions required) -- \textbf{X (1000)}: the tool is not able to detect any bug after 1000 executions. \textbf{PDL}: Partial Deadlock, \textbf{GDL}: Global Deadlock, \textbf{PDL-k}: Partial Deadlock with \textit{k} number of goroutines leaked. \textbf{DL}: A warning for potential deadlock is issued. \textbf{TO/GDL}: The global deadlock is detected because none of goroutines made any progress after 20 seconds, \textbf{CRASH}: The execution paniced because of a flaw in the execution (e.g., send on closed channel panic), \textbf{HANG}: The tool halt for more than 10 minutes.}
\centering
\scalebox{0.72}{
    \input{tabs/comparison}
  }
\label{tab:comparison}
\end{table*}
