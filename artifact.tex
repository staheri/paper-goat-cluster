

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Abstract}

\goat is a framework that takes that
collects traces
study them
debug and visualize
measure coverage

All of above are done through goatlib and tuning parameters such as global deadlock timeout, visualization grain, number of runtime processes, etc.

\goat and its bootstrapping script is available at https://github.com/staheri/goat
We are working on a docker version of goat to make it available for schedule testing through test packages.

\subsection{Artifact check-list (meta-information)}

{\em Obligatory. Use just a few informal keywords in all fields applicable to your artifacts
and remove the rest. This information is needed to find appropriate reviewers and gradually
unify artifact meta information in Digital Libraries.}

{\small
\begin{itemize}
  \item {\bf Algorithm: }Dynamic tracing, testing coverage, schedule exploration, debugging, visualization, and software analysis.
  \item {\bf Program: } Automated source instrumentation that utilize a custom Go runtime to collect traces containing concurrent events. Traces are automatically analyzed to bring insight into the program's behavior, detect deadlocks, and measure concurrent coverage metrics.
  \item {\bf Compilation: } goatlib is the main package that is used in \goat and also usable for Go developers.
  \item {\bf Transformations: } Automatically instrument target source codes with \goat trace handlers.
  \item {\bf Data set: } We used GoBench \cite{yuan-gobench-cgo21} concurrency bugs to evaluate \goat. The data produced by \goat for deadlock detection, visualization and coverage measurement are available in ....
  \item {\bf Run-time environment: } Using a one-time patch, we rebuild the Go runtime from version 1.15.6 and execute \goat in this runtime.
  \item {\bf Hardware: } The version of Go that we use is built for AMD 64 processors.
  \item {\bf Execution: } \goat's executable 
  \item {\bf Metrics: }
  \item {\bf Output: }
  \item {\bf Experiments: }
  \item {\bf How much disk space required (approximately)?: }
  \item {\bf How much time is needed to prepare workflow (approximately)?: }
  \item {\bf How much time is needed to complete experiments (approximately)?: }
  \item {\bf Publicly available?: }
  \item {\bf Code licenses (if publicly available)?: }
  \item {\bf Data licenses (if publicly available)?: }
  \item {\bf Workflow framework used?: }
  \item {\bf Archived (provide DOI)?: }
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Description}

\subsubsection{How to access}

{\em Obligatory}

\subsubsection{Hardware dependencies}

\subsubsection{Software dependencies}

\subsubsection{Data sets}

\subsubsection{Models}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Installation}

{\em Obligatory}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment workflow}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Evaluation and expected results}

{\em Obligatory}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment customization}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Notes}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Methodology}

Submission, reviewing and badging methodology:

\begin{itemize}
  \item \url{https://www.acm.org/publications/policies/artifact-review-badging}
  \item \url{http://cTuning.org/ae/submission-20201122.html}
  \item \url{http://cTuning.org/ae/reviewing-20201122.html}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% When adding this appendix to your paper,
% please remove below part
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
